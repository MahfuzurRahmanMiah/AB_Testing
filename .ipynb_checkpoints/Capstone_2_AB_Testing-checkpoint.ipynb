{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis of Stroke Data\n",
    "By Mahfuz Miah, September 5, 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Synopsis\n",
    "For this project, I performed some exploratory analysis on stroke data. This dataset was found on Kaggle, uploaded by user SaumyaAgarwal and can be retrieved at this link: [Stroke Data](https://www.kaggle.com/asaumya/healthcare-dataset-stroke-data). The dataset we have executed our code on was downloaded on Sept 5th, 2019.\n",
    "\n",
    "The goal of our project was to investigate the relationship between incidence of stroke and other categorical knowledge about a patient. In this dataset, we have data about gender, age, hypertension, heart disease, marriage status, work type, residence type, glucose level BMI, smoking status and incidence of stroke. We are curious to see how these different measures relate to stroke incidence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Background\n",
    "Here are the definitions of the columns of the data:\n",
    "\n",
    "- id-Patient ID\n",
    "- gender-Gender of Patient\n",
    "- age-Age of Patient\n",
    "- hypertension-0 - no hypertension, 1 - suffering from hypertension\n",
    "- heart_disease-0 - no heart disease, 1 - suffering from heart disease\n",
    "- ever_married-Yes/No\n",
    "- work_type-Type of occupation\n",
    "- Residence_type-Area type of residence (Urban/ Rural)\n",
    "- avg_glucose_level-Average Glucose level (measured after meal)\n",
    "- bmi-Body mass index\n",
    "- smoking_status-patientâ€™s smoking status\n",
    "- stroke-0 - no stroke, 1 - suffered stroke"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Understanding and Preparing the Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all necessary libraries\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.cbook as cbook\n",
    "import statistics\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the data\n",
    "\n",
    "filename = 'train_2v.csv'\n",
    "def setdata(filename):\n",
    "    df = pd.read_csv(filename)\n",
    "    # Strip and make column names lowercase so that they are easy to manage. \n",
    "    df.columns = df.columns.str.strip().str.lower()\n",
    "\n",
    "    # Replace characters or remove spaces and make all words lowercase.\n",
    "    df.columns = df.columns.str.replace(' ', '_').str.replace('/', '_').str.replace('(', '').str.replace(')', '')\n",
    "\n",
    "    return df\n",
    "\n",
    "df = setdata(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column values in dataframe:  ['id', 'gender', 'age', 'hypertension', 'heart_disease', 'ever_married', 'work_type', 'residence_type', 'avg_glucose_level', 'bmi', 'smoking_status', 'stroke']\n",
      "                 id           age  hypertension  heart_disease  \\\n",
      "count  43400.000000  43400.000000  43400.000000   43400.000000   \n",
      "mean   36326.142350     42.217894      0.093571       0.047512   \n",
      "std    21072.134879     22.519649      0.291235       0.212733   \n",
      "min        1.000000      0.080000      0.000000       0.000000   \n",
      "25%    18038.500000     24.000000      0.000000       0.000000   \n",
      "50%    36351.500000     44.000000      0.000000       0.000000   \n",
      "75%    54514.250000     60.000000      0.000000       0.000000   \n",
      "max    72943.000000     82.000000      1.000000       1.000000   \n",
      "\n",
      "       avg_glucose_level           bmi        stroke  \n",
      "count       43400.000000  41938.000000  43400.000000  \n",
      "mean          104.482750     28.605038      0.018041  \n",
      "std            43.111751      7.770020      0.133103  \n",
      "min            55.000000     10.100000      0.000000  \n",
      "25%            77.540000     23.200000      0.000000  \n",
      "50%            91.580000     27.700000      0.000000  \n",
      "75%           112.070000     32.900000      0.000000  \n",
      "max           291.050000     97.600000      1.000000  \n"
     ]
    }
   ],
   "source": [
    "# What's inside the file? Let's take a preview.\n",
    "def whats_inside(df):\n",
    "    print(\"Column values in dataframe: \", list(df.columns.values)) \n",
    "    print(df.describe())\n",
    "    \n",
    "whats_inside(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 43400 unique values in column 'id'.\n",
      "There are 3 unique values in column 'gender'.\n",
      "There are 104 unique values in column 'age'.\n",
      "There are 2 unique values in column 'hypertension'.\n",
      "There are 2 unique values in column 'heart_disease'.\n",
      "There are 2 unique values in column 'ever_married'.\n",
      "There are 5 unique values in column 'work_type'.\n",
      "There are 2 unique values in column 'residence_type'.\n",
      "There are 12543 unique values in column 'avg_glucose_level'.\n",
      "There are 555 unique values in column 'bmi'.\n",
      "There are 3 unique values in column 'smoking_status'.\n",
      "There are 2 unique values in column 'stroke'.\n"
     ]
    }
   ],
   "source": [
    "#List of unique values in the df['name'] column\n",
    "def uniqueval(df):\n",
    "    column_names = list(df.columns.values)\n",
    "    for column_name in column_names:\n",
    "        print(\"There are \" + str(df[column_name].nunique()) + \" unique values in column \\'\" + column_name + \"\\'.\")\n",
    "uniqueval(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataframe has 43400 entries and many of the categorical columns have binary information (Yes/No responses in the form of 1 and 0, respectively)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pros and Cons of the Dataset:\n",
    "Pros: \n",
    "- Data is relatively clean and easy to understand\n",
    "- Has a variety of categories one can consider in investigating stroke\n",
    "- Analysis of dataset replicates views present in the literature regarding characteristics that correlate with stroke incidence\n",
    "Cons: \n",
    "- We don't know where the dataset originates from (is it from a particular state or country, when was this dataset collected, etc).\n",
    "- We don't know if there was any bias in collecting this data - this ties in with not knowing the origin of this dataset\n",
    "- We don't have details on # of incidences of stroke for patients; this removes resolution on whether some charactertics are predictive of repeat strokes. \n",
    "- Ethnicity and socioeconomic situation are not listed; these may be contributing (or in this dataframe's case, confounding) variables to consider.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Future Research Plan\n",
    "- Analysis that highlights experimental hypothesis.\n",
    "- A rollout plan showing how to implement and rollout the experiment\n",
    "- An evaluation plan showing what constitutes success in this experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6a. Analysis and Hypothesis\n",
    "We note that increased *blah - fill later* leads to increases in stroke incidence. We hypothesize that giving patients low dose metformin on a daily basis can reduce *blah - fill later* and therefore reduce incidence of stroke.\n",
    "\n",
    "See link for further background: https://www.ncbi.nlm.nih.gov/pubmed/24119365"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6b. Rollout Plan\n",
    "50 patients ages 40-50 that have (x range) of (y measure) will be divided into two groups: 25 participants in the control group and 25 participants in the experimental group (aka A and B groups, in line with A/B testing).\n",
    "\n",
    "Patients in the control group will be given a placebo pill to \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6b. Evaluation Plan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
